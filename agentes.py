import streamlit as st
import os
from typing import Annotated, TypedDict
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.tools.tavily_search import TavilySearchResults
from langgraph.graph import StateGraph, END

# 1. ConfiguraciÃ³n de la PÃ¡gina
st.set_page_config(page_title="F1 PARA NOVATOS", page_icon="ğŸï¸", layout="wide")
st.title("ğŸï¸ F1 PARA NOVATOS")
st.markdown("### Entiende la Ãºltima hora de la FÃ³rmula 1 sin ser ingeniero")

# 2. Sidebar: ConfiguraciÃ³n de API Keys
with st.sidebar:
    st.header("ğŸ”‘ ConfiguraciÃ³n")
    google_key = st.text_input("Google API Key:", type="password")
    tavily_key = st.text_input("Tavily API Key:", type="password")
    
    if google_key and tavily_key:
        os.environ["GOOGLE_API_KEY"] = google_key
        os.environ["TAVILY_API_KEY"] = tavily_key
        st.success("âœ… Boxes listos: APIs configuradas")

# 3. DefiniciÃ³n del Estado y el Grafo
class F1AgentState(TypedDict):
    question: str
    news_context: str
    explanation: str

def tool_search_f1_news(state: F1AgentState):
    """Busca noticias de F1 en tiempo real"""
    search = TavilySearchResults(max_results=4)
    # Refinamos la bÃºsqueda aÃ±adiendo "F1 news" a la pregunta
    query = f"FÃ³rmula 1 latest news: {state['question']}"
    results = search.invoke(query)
    return {"news_context": str(results)}

def generator_f1_expert(state: F1AgentState):
    """Traduce noticias complejas a lenguaje sencillo de F1"""
    llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash') # He actualizado a la versiÃ³n flash 2.0
    
    prompt = f"""
    Eres un comentarista experto de FÃ³rmula 1, amable y muy didÃ¡ctico.
    Tu objetivo es explicarle a un nuevo fan quÃ© estÃ¡ pasando.
    
    CONTEXTO DE NOTICIAS:
    {state['news_context']}
    
    PREGUNTA DEL FAN:
    {state['question']}
    
    INSTRUCCIÃ“N: 
    1. Usa analogÃ­as de coches de calle para que se entienda.
    2. Explica brevemente tÃ©rminos tÃ©cnicos si aparecen (como DRS, degradaciÃ³n, undercut).
    3. MantÃ©n un tono emocionante, Â¡como si estuviÃ©ramos en la parrilla de salida!
    """
    
    response = llm.invoke(prompt)
    return {"explanation": response.content}

# ConstrucciÃ³n del flujo (El Grafo)
workflow = StateGraph(F1AgentState)
workflow.add_node("analista_noticias", tool_search_f1_news)
workflow.add_node("comentarista", generator_f1_expert)

workflow.set_entry_point("analista_noticias")
workflow.add_edge("analista_noticias", "comentarista")
workflow.add_edge("comentarista", END)

app_graph = workflow.compile()

# 4. Interfaz de Usuario
if google_key and tavily_key:
    pregunta = st.text_input("Â¿QuÃ© estÃ¡ pasando en el Paddock?", 
                             placeholder="Ej: Â¿Por quÃ© Ferrari es tan rÃ¡pido hoy? o Â¿QuÃ© es el porpoising?")

    if pregunta:
        with st.spinner("ğŸ Analizando la telemetrÃ­a y noticias..."):
            try:
                inputs = {"question": pregunta}
                resultado = app_graph.invoke(inputs)
                
                st.markdown("---")
                st.subheader("ğŸ™ï¸ AnÃ¡lisis del Experto:")
                st.write(resultado["explanation"])
                
                with st.expander("ğŸ“‘ Fuentes consultadas (Pit Wall Data)"):
                    st.code(resultado["news_context"], language="text")
            
            except Exception as e:
                st.error(f"Â¡Bandera Roja! Error: {str(e)}")
else:
    st.warning("ğŸ‘ˆ Introduce las claves en el sidebar para arrancar el motor.")
